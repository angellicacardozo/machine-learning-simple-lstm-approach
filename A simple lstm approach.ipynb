{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting error and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_error_indexes = np.array([])\n",
    "nn_prediction_indexes = np.array([])\n",
    "nn_true_sequence_indexes = np.array([])\n",
    "nn_best_guess_indexes = np.array([])\n",
    "\n",
    "def store_nn_indexes(error, prediction, true_sequence, best_guess):\n",
    "    global nn_error_indexes\n",
    "    global nn_prediction_indexes\n",
    "    global nn_true_sequence_indexes\n",
    "    global nn_best_guess_indexes\n",
    "    \n",
    "    nn_error_indexes = np.append(nn_error_indexes, error)\n",
    "    nn_prediction_indexes = np.append(nn_prediction_indexes, str(prediction))\n",
    "    nn_true_sequence_indexes = np.append(nn_true_sequence_indexes, str(true_sequence))\n",
    "    nn_best_guess_indexes = np.append(nn_best_guess_indexes, str(best_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Python NN quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int2binary = {}\n",
    "binary_dim = 8\n",
    "\n",
    "largest_number = pow(2,binary_dim)\n",
    "binary = np.unpackbits(\n",
    "    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "input_dim = 2\n",
    "hidden_dim = 16\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our neural network weights/synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synapse_0 = 2*np.random.random((input_dim,hidden_dim)) - 1\n",
    "synapse_1 = 2*np.random.random((hidden_dim,output_dim)) - 1\n",
    "synapse_h = 2*np.random.random((hidden_dim,hidden_dim)) - 1\n",
    "\n",
    "synapse_0_update = np.zeros_like(synapse_0)\n",
    "synapse_1_update = np.zeros_like(synapse_1)\n",
    "synapse_h_update = np.zeros_like(synapse_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10000):\n",
    "    \n",
    "    # generate a simple addition problem (a + b = c)\n",
    "    a_int = np.random.randint(largest_number/2) # int version\n",
    "    a = int2binary[a_int] # binary encoding\n",
    "\n",
    "    b_int = np.random.randint(largest_number/2) # int version\n",
    "    b = int2binary[b_int] # binary encoding\n",
    "\n",
    "    # true answer\n",
    "    c_int = a_int + b_int\n",
    "    c = int2binary[c_int]\n",
    "    \n",
    "    # where we'll store our best guess (binary encoded)\n",
    "    d = np.zeros_like(c)\n",
    "\n",
    "    overallError = 0\n",
    "    \n",
    "    layer_2_deltas = list()\n",
    "    layer_1_values = list()\n",
    "    layer_1_values.append(np.zeros(hidden_dim))\n",
    "    \n",
    "    # moving along the positions in the binary encoding\n",
    "    for position in range(binary_dim):\n",
    "        \n",
    "        # generate input and output\n",
    "        X = np.array([[a[binary_dim - position - 1],b[binary_dim - position - 1]]])\n",
    "        y = np.array([[c[binary_dim - position - 1]]]).T\n",
    "\n",
    "        # hidden layer (input ~+ prev_hidden)\n",
    "        layer_1 = sigmoid(np.dot(X,synapse_0) + np.dot(layer_1_values[-1],synapse_h))\n",
    "\n",
    "        # output layer (new binary representation)\n",
    "        layer_2 = sigmoid(np.dot(layer_1,synapse_1))\n",
    "\n",
    "        # did we miss?... if so, by how much?\n",
    "        layer_2_error = y - layer_2\n",
    "        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_derivative(layer_2))\n",
    "        overallError += np.abs(layer_2_error[0])\n",
    "    \n",
    "        # decode estimate so we can print it out\n",
    "        d[binary_dim - position - 1] = np.round(layer_2[0][0])\n",
    "        \n",
    "        # store hidden layer so we can use it in the next timestep\n",
    "        layer_1_values.append(copy.deepcopy(layer_1))\n",
    "    \n",
    "    future_layer_1_delta = np.zeros(hidden_dim)\n",
    "    \n",
    "    for position in range(binary_dim):\n",
    "        \n",
    "        X = np.array([[a[position],b[position]]])\n",
    "        layer_1 = layer_1_values[-position-1]\n",
    "        prev_layer_1 = layer_1_values[-position-2]\n",
    "        \n",
    "        # error at output layer\n",
    "        layer_2_delta = layer_2_deltas[-position-1]\n",
    "        # error at hidden layer\n",
    "        layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(layer_1)\n",
    "\n",
    "        # let's update all our weights so we can try again\n",
    "        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n",
    "        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n",
    "        synapse_0_update += X.T.dot(layer_1_delta)\n",
    "        \n",
    "        future_layer_1_delta = layer_1_delta\n",
    "    \n",
    "\n",
    "    synapse_0 += synapse_0_update * alpha\n",
    "    synapse_1 += synapse_1_update * alpha\n",
    "    synapse_h += synapse_h_update * alpha    \n",
    "\n",
    "    synapse_0_update *= 0\n",
    "    synapse_1_update *= 0\n",
    "    synapse_h_update *= 0\n",
    "    \n",
    "    # print out progress\n",
    "    if(j % 1000 == 0):\n",
    "        out = 0\n",
    "        for index,x in enumerate(reversed(d)):\n",
    "            out += x*pow(2,index)\n",
    "        \n",
    "        store_nn_indexes(overallError, d, c, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output NN indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >Best guess</th> \n",
       "        <th class=\"col_heading level0 col1\" >Error</th> \n",
       "        <th class=\"col_heading level0 col2\" >Prediction</th> \n",
       "        <th class=\"col_heading level0 col3\" >True sequence</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow0_col1\" class=\"data row0 col1\" >3.97245</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow0_col2\" class=\"data row0 col2\" >[0 0 0 0 0 0 0 0]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow0_col3\" class=\"data row0 col3\" >[1 0 0 1 0 0 1 1]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow1_col0\" class=\"data row1 col0\" >0</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow1_col1\" class=\"data row1 col1\" >3.80596</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow1_col2\" class=\"data row1 col2\" >[0 0 0 0 0 0 0 0]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow1_col3\" class=\"data row1 col3\" >[1 0 0 0 0 1 0 0]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow2_col0\" class=\"data row2 col0\" >127</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow2_col1\" class=\"data row2 col1\" >4.32286</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow2_col2\" class=\"data row2 col2\" >[0 1 1 1 1 1 1 1]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow2_col3\" class=\"data row2 col3\" >[0 1 0 0 0 0 0 1]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow3_col1\" class=\"data row3 col1\" >4.34391</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow3_col2\" class=\"data row3 col2\" >[0 0 0 0 0 0 0 0]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow3_col3\" class=\"data row3 col3\" >[1 0 1 1 1 1 1 1]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow4_col0\" class=\"data row4 col0\" >17</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow4_col1\" class=\"data row4 col1\" >3.2609</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow4_col2\" class=\"data row4 col2\" >[0 0 0 1 0 0 0 1]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow4_col3\" class=\"data row4 col3\" >[1 0 0 1 1 0 0 1]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row5\" >5</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow5_col0\" class=\"data row5 col0\" >197</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow5_col1\" class=\"data row5 col1\" >1.22145</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow5_col2\" class=\"data row5 col2\" >[1 1 0 0 0 1 0 1]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow5_col3\" class=\"data row5 col3\" >[1 1 0 0 0 1 0 1]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row6\" >6</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow6_col0\" class=\"data row6 col0\" >116</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow6_col1\" class=\"data row6 col1\" >0.815454</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow6_col2\" class=\"data row6 col2\" >[0 1 1 1 0 1 0 0]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow6_col3\" class=\"data row6 col3\" >[0 1 1 1 0 1 0 0]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row7\" >7</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow7_col0\" class=\"data row7 col0\" >227</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow7_col1\" class=\"data row7 col1\" >0.59905</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow7_col2\" class=\"data row7 col2\" >[1 1 1 0 0 0 1 1]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow7_col3\" class=\"data row7 col3\" >[1 1 1 0 0 0 1 1]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row8\" >8</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow8_col0\" class=\"data row8 col0\" >110</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow8_col1\" class=\"data row8 col1\" >0.456702</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow8_col2\" class=\"data row8 col2\" >[0 1 1 0 1 1 1 0]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow8_col3\" class=\"data row8 col3\" >[0 1 1 0 1 1 1 0]</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227ca\" class=\"row_heading level0 row9\" >9</th> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow9_col0\" class=\"data row9 col0\" >115</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow9_col1\" class=\"data row9 col1\" >0.358321</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow9_col2\" class=\"data row9 col2\" >[0 1 1 1 0 0 1 1]</td> \n",
       "        <td id=\"T_3f7ebe2c_a866_11e7_a92b_080027c227carow9_col3\" class=\"data row9 col3\" >[0 1 1 1 0 0 1 1]</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0d752aaf60>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'Error' : nn_error_indexes\n",
    "        ,'Prediction': nn_prediction_indexes\n",
    "        ,'True sequence': nn_true_sequence_indexes\n",
    "        ,'Best guess': nn_best_guess_indexes\n",
    "})\n",
    "df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network memory\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
